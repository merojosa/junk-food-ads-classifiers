{"cells":[{"cell_type":"markdown","metadata":{"id":"EnzsjpMSAzB3"},"source":["# Junk Food Multi-label Classification with CLIP using ViT\n","\n","This notebook implements a **CLIP** model for image classification from a **COCO JSON dataset**."]},{"cell_type":"markdown","metadata":{"id":"6h0eXidyzCEK"},"source":["## Before you start\n","\n","Make sure you have access to GPU. In case of any problems, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, click `Save` and try again."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZdVia1hzNQK","outputId":"46d8f53d-4848-46fd-d22a-c0fb2a2fc7b7","executionInfo":{"status":"ok","timestamp":1768718506474,"user_tz":360,"elapsed":159,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jan 18 06:41:56 2026       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iiA-yIY_Sntv","outputId":"103506ac-adad-4f88-c3a3-a261c27b9f94","executionInfo":{"status":"ok","timestamp":1768718506547,"user_tz":360,"elapsed":72,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["HOME: /content\n","/content/datasets\n"]}],"source":["import os\n","HOME = os.getcwd()\n","print(\"HOME:\", HOME)\n","!mkdir -p {HOME}/datasets\n","%cd {HOME}/datasets"]},{"cell_type":"markdown","metadata":{"id":"cMwNCMGkzXbo"},"source":["## Install packages using pip\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P8Sq8dbzyRSl","outputId":"91446f63-2c82-4ff2-ea4c-a38a9b51c82b","executionInfo":{"status":"ok","timestamp":1768718516671,"user_tz":360,"elapsed":10121,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: roboflow==1.2.11 in /usr/local/lib/python3.12/dist-packages (1.2.11)\n","Requirement already satisfied: open-clip-torch==3.2.0 in /usr/local/lib/python3.12/dist-packages (3.2.0)\n","Requirement already satisfied: pillow==11.3.0 in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n","Requirement already satisfied: torchvision==0.24.0 in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (2026.1.4)\n","Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (3.7)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.4.9)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (3.10.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (2.0.2)\n","Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (4.10.0.84)\n","Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.1.1)\n","Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.5.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (2.9.0.post0)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.2.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (2.32.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.17.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (2.5.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (6.0.3)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.0.0)\n","Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.2.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from open-clip-torch==3.2.0) (2025.11.3)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from open-clip-torch==3.2.0) (6.3.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from open-clip-torch==3.2.0) (0.36.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from open-clip-torch==3.2.0) (0.7.0)\n","Requirement already satisfied: timm>=1.0.17 in /usr/local/lib/python3.12/dist-packages (from open-clip-torch==3.2.0) (1.0.24)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (3.20.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0) (1.3.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->open-clip-torch==3.2.0) (0.2.14)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open-clip-torch==3.2.0) (25.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open-clip-torch==3.2.0) (1.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0) (3.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow==1.2.11) (1.3.3)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow==1.2.11) (4.61.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow==1.2.11) (3.3.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow==1.2.11) (3.4.4)\n"]}],"source":["!pip install roboflow==1.2.11 open-clip-torch==3.2.0 pillow==11.3.0 torch==2.9.0 torchvision==0.24.0"]},{"cell_type":"markdown","metadata":{"id":"dQ1JN1BwQJSy"},"source":["## Download dataset from Roboflow\n","\n","Don't forget to change the `API_KEY` with your dataset key.\n","\n","The dataset from Roboflow comes in COCO format"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwEc0qz7QJlC","outputId":"470a58d1-2622-4fb4-89d5-3f985c5535ae","executionInfo":{"status":"ok","timestamp":1768718519691,"user_tz":360,"elapsed":3019,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]}],"source":["from roboflow import Roboflow\n","from google.colab import userdata\n","\n","rf = Roboflow(api_key=userdata.get('ROBOFLOW_API_KEY'))\n","project = rf.workspace(userdata.get('ROBOFLOW_WORKSPACE_ID')).project(userdata.get('ROBOFLOW_PROJECT_ID'))\n","version = project.version(userdata.get('ROBOFLOW_DATASET_VERSION'))\n","dataset = version.download(\"coco\")\n","\n","DATASET_PATH = \"datasets/Junk-Food-Detection-10/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58gaxSw32zPx","outputId":"5fc74789-a7a1-40ce-996f-08344b75e0b3","executionInfo":{"status":"ok","timestamp":1768718519700,"user_tz":360,"elapsed":7,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["%cd {HOME}"]},{"cell_type":"markdown","metadata":{"id":"ZJ_kzpGoD3Ht"},"source":["## Classes recollection\n","\n","We get the classes from the original dataset. As we will use CLIP, let's transform the classes into natural language."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awjCo_sbD2o3","outputId":"7d82a328-af6d-42e0-c9ee-3ade0f38e04e","executionInfo":{"status":"ok","timestamp":1768718519831,"user_tz":360,"elapsed":126,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['french_fries', 'fried_chicken', 'hamburger', 'ice_cream', 'junk_food_logo', 'pizza', 'soda']\n"]}],"source":["import json\n","from pathlib import Path\n","\n","folders = ['train', 'test', 'valid']\n","all_categories = {}\n","\n","for folder in folders:\n","    json_path = DATASET_PATH + folder + \"/_annotations.coco.json\"\n","\n","    try:\n","        with open(json_path, 'r') as f:\n","            data = json.load(f)\n","            categories = data.get('categories', [])\n","\n","            for category in categories:\n","                cat_id = category['id']\n","                cat_name = category['name']\n","                cat_supercategory = category.get('supercategory', 'none')\n","\n","                # Skip the junk-food category for this particular dataset (it means nothing)\n","                if cat_name == 'junk-food':\n","                  continue\n","\n","                if cat_name not in all_categories:\n","                    all_categories[cat_name] = {\n","                        'id': cat_id,\n","                        'name': cat_name,\n","                        'supercategory': cat_supercategory\n","                    }\n","\n","    except FileNotFoundError:\n","        print(f\"Warning: {json_path} not found\")\n","    except json.JSONDecodeError:\n","        print(f\"Error: {json_path} is not a valid JSON file\")\n","\n","NATURAL_LANGUAGE_TO_CLASS_MAP = {\n","  'french fries': 'french_fries',\n","  'fried chicken': 'fried_chicken',\n","  'hamburger': 'hamburger',\n","  'ice cream': 'ice_cream',\n","  'junk food logo': 'junk_food_logo',\n","  'pizza': 'pizza',\n","  'soda': 'soda'\n","}\n","CLASS_TO_NATURAL_LANGUAGE_MAP = {v: k for k, v in NATURAL_LANGUAGE_TO_CLASS_MAP.items()}\n","\n","classes_from_dataset = [cat_name for cat_name in CLASS_TO_NATURAL_LANGUAGE_MAP.keys()]\n","\n","print(\"Classes:\", classes_from_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zcdn3Amv3sTv"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"m9a8DSyb6GVQ"},"source":["## Prepare OpenCLIP model\n","\n","We use promp ensembles and a threashold of 0.2."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TFOq4krq6aJk","outputId":"7cc69274-7cb5-4b0d-d8ab-c127f29ad894","executionInfo":{"status":"ok","timestamp":1768718536395,"user_tz":360,"elapsed":16515,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n"]}],"source":["import torch\n","import open_clip\n","from PIL import Image\n","from collections import defaultdict\n","import json\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, _, preprocess = open_clip.create_model_and_transforms(\n","    \"ViT-B-16\",\n","    pretrained=\"laion2b_s34b_b88k\"\n",")\n","tokenizer = open_clip.get_tokenizer(\"ViT-B-16\")\n","model = model.to(device)\n","model.eval()\n","\n","def classify_images_with_clip(dataset_part, classes):\n","\n","    with open(DATASET_PATH + dataset_part + \"/\" + \"_annotations.coco.json\", \"r\") as f:\n","        coco_data = json.load(f)\n","\n","    # Build mappings\n","    category_id_to_name = {cat[\"id\"]: cat[\"name\"] for cat in coco_data[\"categories\"]}\n","    image_id_to_filename = {img[\"id\"]: img[\"file_name\"] for img in coco_data[\"images\"]}\n","\n","    # Group annotations by image_id\n","    image_annotations = defaultdict(list)\n","    for ann in coco_data[\"annotations\"]:\n","        image_id = ann[\"image_id\"]\n","        category_name = category_id_to_name[ann[\"category_id\"]]\n","        image_annotations[image_id].append(category_name)\n","\n","    # Get ground truth labels per image (unique categories)\n","    ground_truth = {}\n","    for image_id, categories in image_annotations.items():\n","        filename = image_id_to_filename[image_id]\n","        unique_categories = list(set(categories))\n","        ground_truth[filename] = unique_categories\n","\n","    # Prompt ensembling\n","    templates = [\n","        \"a photo of {}\",\n","        \"a picture of {}\",\n","        \"an image containing {}\",\n","        \"a close-up photo of {}\",\n","        \"an ad containing {}\"\n","    ]\n","\n","    # Encode text features once\n","    with torch.no_grad():\n","        text_features = []\n","\n","        for cls in classes:\n","            prompts = [t.format(CLASS_TO_NATURAL_LANGUAGE_MAP[cls]) for t in templates]\n","            tokens = tokenizer(prompts).to(device)\n","\n","            embeddings = model.encode_text(tokens)\n","            embeddings /= embeddings.norm(dim=-1, keepdim=True)\n","\n","            class_embedding = embeddings.mean(dim=0)\n","            class_embedding /= class_embedding.norm()\n","\n","            text_features.append(class_embedding)\n","\n","        text_features = torch.stack(text_features)  # [num_classes, embed_dim]\n","\n","    # Multi-label threshold (cosine similarity space)\n","    classification_threshold = 0.2  # Adjust this based on your data\n","\n","    results = {}\n","    image_paths = [img[\"file_name\"] for img in coco_data[\"images\"]]\n","\n","    for image_path in image_paths:\n","        try:\n","            image = Image.open(DATASET_PATH + dataset_part + \"/\" + image_path).convert(\"RGB\")\n","            image_tensor = preprocess(image).unsqueeze(0).to(device)\n","\n","            with torch.no_grad():\n","                image_features = model.encode_image(image_tensor)\n","                image_features /= image_features.norm(dim=-1, keepdim=True)\n","\n","                # Cosine similarity per class\n","                similarities = (image_features @ text_features.T).squeeze(0).cpu()\n","\n","            # Independent multi-label decision\n","            predicted_labels = []\n","            predicted_scores = {}\n","\n","            for idx, score in enumerate(similarities):\n","                score_value = score.item()\n","                predicted_scores[classes[idx]] = score_value\n","\n","                if score_value >= classification_threshold:\n","                    predicted_labels.append(classes[idx])\n","\n","            # Store all predicted labels and scores\n","            results[image_path] = {\n","                \"labels\": predicted_labels,\n","                \"scores\": predicted_scores\n","            }\n","\n","        except FileNotFoundError:\n","            raise FileNotFoundError(\n","                f\"Image file not found: {image_path}. Cannot continue processing.\"\n","            )\n","\n","    return results, ground_truth, image_paths"]},{"cell_type":"markdown","metadata":{"id":"GpHdZm1xmQCc"},"source":["## Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0_9F9TFwmPb0"},"outputs":[],"source":["def evaluate_predictions(image_paths, ground_truth, results, classes):\n","    # Per-class metrics\n","    class_metrics = {cls: {'tp': 0, 'fp': 0, 'fn': 0} for cls in classes}\n","\n","    # Overall metrics (micro-averaged)\n","    total_tp = 0\n","    total_fp = 0\n","    total_fn = 0\n","\n","    for image_path in image_paths:\n","        true_labels = set(ground_truth.get(image_path, []))\n","        pred_entry = results.get(image_path, {})\n","        pred_labels = set(pred_entry.get(\"labels\", []))\n","\n","        # Evaluate each class independently\n","        for cls in classes:\n","            true_positive = cls in true_labels\n","            pred_positive = cls in pred_labels\n","\n","            if true_positive and pred_positive:\n","                class_metrics[cls]['tp'] += 1\n","                total_tp += 1\n","            elif not true_positive and pred_positive:\n","                class_metrics[cls]['fp'] += 1\n","                total_fp += 1\n","            elif true_positive and not pred_positive:\n","                class_metrics[cls]['fn'] += 1\n","                total_fn += 1\n","\n","    # Calculate macro-F1\n","    macro_f1 = 0\n","    for cls in classes:\n","        tp = class_metrics[cls]['tp']\n","        fp = class_metrics[cls]['fp']\n","        fn = class_metrics[cls]['fn']\n","\n","        precision = (tp / (tp + fp)) if (tp + fp) > 0 else 0\n","        recall = (tp / (tp + fn)) if (tp + fn) > 0 else 0\n","        f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0\n","        macro_f1 += f1\n","\n","    macro_f1 = (macro_f1 / len(classes) * 100) if len(classes) > 0 else 0\n","\n","    # Calculate micro-F1\n","    micro_precision = (total_tp / (total_tp + total_fp)) if (total_tp + total_fp) > 0 else 0\n","    micro_recall = (total_tp / (total_tp + total_fn)) if (total_tp + total_fn) > 0 else 0\n","    micro_f1 = (2 * micro_precision * micro_recall / (micro_precision + micro_recall)) if (micro_precision + micro_recall) > 0 else 0\n","\n","    # Calculate subset accuracy (exact match)\n","    exact_matches = sum(\n","        1 for path in image_paths\n","        if set(ground_truth.get(path, [])) == set(results.get(path, {}).get(\"labels\", []))\n","    )\n","    subset_accuracy = (exact_matches / len(image_paths) * 100) if len(image_paths) > 0 else 0\n","\n","    return {\n","        'micro_f1_score': micro_f1 * 100,\n","        'macro_f1_score': macro_f1,\n","        'subset_accuracy': subset_accuracy\n","    }"]},{"cell_type":"markdown","metadata":{"id":"MfEu3iDK98II"},"source":["## Prediction on validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DMa8ZtUL-Cuc","outputId":"da0b9755-80cf-4321-b146-a656abb23c84","executionInfo":{"status":"ok","timestamp":1768718545344,"user_tz":360,"elapsed":8931,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Subset Accuracy: 46.59%\n","Micro F1: 48.01%\n","Macro F1: 55.50%\n"]}],"source":["valid_results, valid_ground_truth, valid_image_paths = classify_images_with_clip(\n","    dataset_part=\"valid\",\n","    classes=classes_from_dataset,\n",")\n","\n","valid_metrics = evaluate_predictions(\n","    image_paths=valid_image_paths,\n","    ground_truth=valid_ground_truth,\n","    results=valid_results,\n","    classes=classes_from_dataset,\n",")\n","\n","print(f\"Subset Accuracy: {valid_metrics['subset_accuracy']:.2f}%\")\n","print(f\"Micro F1: {valid_metrics['micro_f1_score']:.2f}%\")\n","print(f\"Macro F1: {valid_metrics['macro_f1_score']:.2f}%\")"]},{"cell_type":"markdown","metadata":{"id":"ySrLsbRGZNmZ"},"source":["## Run model on test set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7RaDCFPZYXd","outputId":"dccd6067-9754-428e-9044-fff09d34ec62","executionInfo":{"status":"ok","timestamp":1768718549625,"user_tz":360,"elapsed":4280,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","TEST SET METRICS\n","==================================================\n","Subset Accuracy: 0.4679\n","Micro F1:        0.4816\n","Macro F1:        0.5598\n","\n","==================================================\n","F1 SCORE PER CLASS\n","==================================================\n","french_fries: 0.5185\n","fried_chicken: 0.6667\n","hamburger: 0.7333\n","ice_cream: 0.4865\n","junk_food_logo: 0.1856\n","pizza: 0.7222\n","soda: 0.6061\n"]}],"source":["test_results, test_ground_truth, test_image_paths = classify_images_with_clip(\n","    dataset_part=\"test\",\n","    classes=classes_from_dataset,\n",")\n","\n","test_metrics = evaluate_predictions(\n","    image_paths=test_image_paths,\n","    ground_truth=test_ground_truth,\n","    results=test_results,\n","    classes=classes_from_dataset,\n",")\n","\n","print(\"\\n\" + \"=\" * 50)\n","print(\"TEST SET METRICS\")\n","print(\"=\" * 50)\n","print(f\"Subset Accuracy: {test_metrics['subset_accuracy'] / 100:.4f}\")\n","print(f\"Micro F1:        {test_metrics['micro_f1_score'] / 100:.4f}\")\n","print(f\"Macro F1:        {test_metrics['macro_f1_score'] / 100:.4f}\")\n","\n","# F1 score per class\n","print(\"\\n\" + \"=\" * 50)\n","print(\"F1 SCORE PER CLASS\")\n","print(\"=\" * 50)\n","for cls in classes_from_dataset:\n","    tp = fp = fn = 0\n","    for image_path in test_image_paths:\n","        true_labels = set(test_ground_truth.get(image_path, []))\n","        pred_labels = set(test_results.get(image_path, {}).get('labels', []))\n","        if cls in true_labels and cls in pred_labels:\n","            tp += 1\n","        elif cls not in true_labels and cls in pred_labels:\n","            fp += 1\n","        elif cls in true_labels and cls not in pred_labels:\n","            fn += 1\n","    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n","    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n","    print(f\"{cls}: {f1:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"3RybNi0U1ijI"},"source":["## Real images test\n","\n","Let's test the model on random images from the test set with multi-label prediction visualization."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1uViIBrbA4BQLMSTyrHxOpYAYRcif6-Y-"},"id":"IGi3oDVB1ijI","executionInfo":{"status":"ok","timestamp":1768718552275,"user_tz":360,"elapsed":2649,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}},"outputId":"81e62ba4-1407-466b-bd03-746347ef54fb"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import random\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","\n","# Filter to only images that have at least one label (interesting images)\n","positive_test_images = [img for img in test_image_paths if len(test_ground_truth.get(img, [])) > 0]\n","\n","# Pick 5 random test images with labels\n","random_images = random.sample(positive_test_images, min(5, len(positive_test_images)))\n","\n","# Define colors for each class\n","class_colors = {\n","    \"french_fries\": \"#F39C12\",\n","    \"fried_chicken\": \"#E67E22\",\n","    \"hamburger\": \"#8B4513\",\n","    \"ice_cream\": \"#96CEB4\",\n","    \"junk_food_logo\": \"#FFEAA7\",\n","    \"pizza\": \"#FD79A8\",\n","    \"soda\": \"#A29BFE\"\n","}\n","\n","threshold = 0.2\n","\n","for idx, random_image_path in enumerate(random_images, 1):\n","    print(f\"{'='*60}\")\n","    print(f\"Image {idx}/5: {random_image_path}\")\n","    print('='*60)\n","\n","    # Load the image\n","    image = Image.open(DATASET_PATH + \"test/\" + random_image_path).convert(\"RGB\")\n","    image_input = preprocess(image).unsqueeze(0).to(device)\n","\n","    # Run inference\n","    predicted_labels = []\n","    all_probs = {}\n","\n","    with torch.no_grad():\n","        image_features = model.encode_image(image_input)\n","        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n","\n","        for class_name in classes_from_dataset:\n","            natural_language = CLASS_TO_NATURAL_LANGUAGE_MAP[class_name]\n","            prompts = [\n","                f\"a photo of {natural_language}\",\n","                f\"an advertisement featuring {natural_language}\",\n","                f\"a billboard showing {natural_language}\",\n","                f\"{natural_language} in an ad\",\n","                f\"commercial with {natural_language}\"\n","            ]\n","\n","            text_tokens = tokenizer(prompts).to(device)\n","            text_features = model.encode_text(text_tokens)\n","            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n","            text_features = text_features.mean(dim=0, keepdim=True)\n","            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n","\n","            similarity = (image_features @ text_features.T).squeeze().item()\n","            all_probs[class_name] = similarity\n","\n","            if similarity >= threshold:\n","                predicted_labels.append(class_name)\n","\n","    # Get true labels\n","    true_labels = test_ground_truth.get(random_image_path, [])\n","\n","    # Display the image with predictions\n","    fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n","    ax.imshow(image)\n","    ax.axis(\"off\")\n","\n","    # Create label badges at the bottom\n","    num_labels = len(predicted_labels) if predicted_labels else 1\n","    badge_width = 0.18\n","    badge_spacing = 0.02\n","    total_width = num_labels * badge_width + (num_labels - 1) * badge_spacing\n","    start_x = 0.5 - total_width / 2\n","\n","    if predicted_labels:\n","        for i, label in enumerate(predicted_labels):\n","            x_pos = start_x + i * (badge_width + badge_spacing)\n","            color = class_colors.get(label, \"#95A5A6\")\n","\n","            badge = mpatches.FancyBboxPatch(\n","                (x_pos, -0.08), badge_width, 0.05,\n","                boxstyle=\"round,pad=0.01\",\n","                facecolor=color,\n","                edgecolor=\"white\",\n","                linewidth=2,\n","                transform=ax.transAxes,\n","                clip_on=False\n","            )\n","            ax.add_patch(badge)\n","            ax.text(\n","                x_pos + badge_width / 2, -0.055,\n","                label.upper(),\n","                transform=ax.transAxes,\n","                fontsize=9,\n","                fontweight=\"bold\",\n","                color=\"white\" if label != \"junk_food_logo\" else \"black\",\n","                ha=\"center\",\n","                va=\"center\"\n","            )\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    print(f\"Predicted labels: {predicted_labels if predicted_labels else '(none)'}\")\n","    print(f\"True labels: {true_labels if true_labels else '(none)'}\")\n","    print(f\"All class similarities:\")\n","    for cls, prob in sorted(all_probs.items(), key=lambda x: x[1], reverse=True):\n","        marker = \">\" if prob >= threshold else \" \"\n","        print(f\"  {marker} {cls}: {prob:.3f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}