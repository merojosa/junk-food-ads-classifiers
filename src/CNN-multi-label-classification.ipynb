{"cells":[{"cell_type":"markdown","metadata":{"id":"EvlC2Rnni7oi"},"source":["# Junk Food Multi-label Classification with KNN\n","\n","This notebook implements a **CNN** model for image classification from a **COCO JSON dataset**."]},{"cell_type":"markdown","metadata":{"id":"gcbOFYLzjV6B"},"source":["## Before you start\n","\n","Make sure you have access to GPU. In case of any problems, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, click `Save` and try again."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjlhPWyOjWsp","outputId":"b91177bf-ddb3-472b-c409-4076ecab73cc","executionInfo":{"status":"ok","timestamp":1768718501606,"user_tz":360,"elapsed":204,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jan 18 06:41:51 2026       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0             68W /  400W |       0MiB /  40960MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5H3H-YHDkdqz","outputId":"702004a9-2c27-439b-e1c2-70d412b10dec","executionInfo":{"status":"ok","timestamp":1768718501616,"user_tz":360,"elapsed":7,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["HOME: /content\n"]}],"source":["import os\n","HOME = os.getcwd()\n","print(\"HOME:\", HOME)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xe-7ZMI6kebP","outputId":"37cd1166-2f9b-4542-ff5d-0f0eaca2a54e","executionInfo":{"status":"ok","timestamp":1768718501711,"user_tz":360,"elapsed":90,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/datasets\n"]}],"source":["!mkdir -p {HOME}/datasets\n","%cd {HOME}/datasets\n"]},{"cell_type":"markdown","metadata":{"id":"mH1xxtULn2xV"},"source":["## Install packages using pip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"xvTEqLaOkjPL","outputId":"bf41cb10-064c-4ffa-9173-484e12e5d4cc","executionInfo":{"status":"ok","timestamp":1768718506269,"user_tz":360,"elapsed":4538,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: roboflow==1.2.11 in /usr/local/lib/python3.12/dist-packages (1.2.11)\n","Requirement already satisfied: tensorflow==2.19.0 in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (2026.1.4)\n","Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (3.7)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.4.9)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (3.10.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (2.0.2)\n","Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (4.10.0.84)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (11.3.0)\n","Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.1.1)\n","Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.5.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (2.9.0.post0)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.2.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (2.32.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.17.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (2.5.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (6.0.3)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.0.0)\n","Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from roboflow==1.2.11) (1.2.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (25.12.19)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (0.7.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (5.29.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (75.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (2.0.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.76.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.10.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.15.1)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (0.5.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.19.0) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (0.18.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow==1.2.11) (3.4.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (3.10)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (3.1.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow==1.2.11) (1.3.3)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow==1.2.11) (4.61.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow==1.2.11) (3.3.1)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0) (3.0.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0) (0.1.2)\n"]}],"source":["!pip install roboflow==1.2.11 tensorflow==2.19.0"]},{"cell_type":"markdown","metadata":{"id":"_CCGi6EWnsMN"},"source":["## Download dataset from Roboflow\n","\n","Don't forget to change the `API_KEY` with your dataset key.\n","\n","We replicate your original dataset setup. Even though the dataset is labeled for object detection, we’ll use the full image classification approach with KNN. Labels will be derived from the most frequent class per image."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XM4b5M09kj3D","outputId":"1233b954-5b53-47b6-8206-90e8863ba699","executionInfo":{"status":"ok","timestamp":1768718508701,"user_tz":360,"elapsed":2425,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]}],"source":["from roboflow import Roboflow\n","from google.colab import userdata\n","\n","rf = Roboflow(api_key=userdata.get('ROBOFLOW_API_KEY'))\n","project = rf.workspace(userdata.get('ROBOFLOW_WORKSPACE_ID')).project(userdata.get('ROBOFLOW_PROJECT_ID'))\n","version = project.version(userdata.get('ROBOFLOW_DATASET_VERSION'))\n","dataset = version.download(\"coco\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71fxf9Tsktei","outputId":"cbc71257-a096-49e9-e326-171885017fc5","executionInfo":{"status":"ok","timestamp":1768718508708,"user_tz":360,"elapsed":5,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["%cd {HOME}"]},{"cell_type":"markdown","metadata":{"id":"LM3porFAovJj"},"source":["## Convert COCO detection dataset to EfficientNetV2 multi-label classification\n","\n","For labeling, we use the 7 classes from the COCO JSON dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_QaNLLGlie3V","outputId":"0b8ec462-9ac7-47ef-b26e-cbdb14dd9dad","executionInfo":{"status":"ok","timestamp":1768718518042,"user_tz":360,"elapsed":9333,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded train set: 4614 images, 7 classes\n","Labels shape: (4614, 7)\n"]}],"source":["import json\n","import os\n","import numpy as np\n","from PIL import Image\n","from pathlib import Path\n","from typing import Tuple, List, Dict\n","import tensorflow as tf\n","\n","\n","def load_coco_annotations(json_path: str) -> Tuple[Dict, List, Dict]:\n","    with open(json_path, 'r') as f:\n","        coco_data = json.load(f)\n","\n","    # Create mappings\n","    images_dict = {img['id']: img for img in coco_data['images']}\n","\n","    # Filter out \"junk-food\" category\n","    categories = [cat for cat in coco_data['categories'] if cat['name'] != 'junk-food']\n","\n","    # Get IDs of categories to keep\n","    valid_category_ids = {cat['id'] for cat in categories}\n","\n","    # Group annotations by image_id, filtering out junk-food annotations\n","    annotations_by_image = {}\n","    for ann in coco_data['annotations']:\n","        # Skip if this annotation is for junk-food\n","        if ann['category_id'] not in valid_category_ids:\n","            continue\n","\n","        image_id = ann['image_id']\n","        if image_id not in annotations_by_image:\n","            annotations_by_image[image_id] = []\n","        annotations_by_image[image_id].append(ann['category_id'])\n","\n","    return annotations_by_image, categories, images_dict\n","\n","\n","def create_label_mapping(categories: List[Dict]) -> Tuple[Dict, Dict, int]:\n","    \"\"\"\n","    Create category ID to index mapping for multi-label classification.\n","    \"\"\"\n","    # Sort categories by ID for consistency\n","    sorted_categories = sorted(categories, key=lambda x: x['id'])\n","\n","    cat_id_to_idx = {cat['id']: idx for idx, cat in enumerate(sorted_categories)}\n","    idx_to_cat_id = {idx: cat['id'] for idx, cat in enumerate(sorted_categories)}\n","    num_classes = len(categories)\n","\n","    return cat_id_to_idx, idx_to_cat_id, num_classes\n","\n","\n","def transform_coco_to_multilabel(\n","    dataset_location: str,\n","    image_size: Tuple[int, int],\n","    subset: str = 'train',\n",") -> Tuple[np.ndarray, np.ndarray, Dict]:\n","    \"\"\"\n","    Transform COCO JSON dataset into format for EfficientNetV2 multi-label classification.\n","    \"\"\"\n","    # Construct paths\n","    subset_path = os.path.join(dataset_location, subset)\n","    json_path = os.path.join(subset_path, '_annotations.coco.json')\n","\n","    if not os.path.exists(json_path):\n","        raise FileNotFoundError(f\"Annotations file not found at {json_path}\")\n","\n","    # Load COCO annotations\n","    annotations_by_image, categories, images_dict = load_coco_annotations(json_path)\n","\n","    # Create label mappings\n","    cat_id_to_idx, idx_to_cat_id, num_classes = create_label_mapping(categories)\n","\n","    # Prepare lists for data\n","    image_paths = []\n","    labels_list = []\n","\n","    # Process each image\n","    for image_id, image_info in images_dict.items():\n","        # Get image path\n","        image_filename = image_info['file_name']\n","        image_path = os.path.join(subset_path, image_filename)\n","\n","        # Check if image exists\n","        if not os.path.exists(image_path):\n","            print(f\"Warning: Image not found: {image_path}\")\n","            continue\n","\n","        # Create multi-hot encoded label\n","        label_vector = np.zeros(num_classes, dtype=np.float32)\n","\n","        # Get annotations for this image\n","        if image_id in annotations_by_image:\n","            category_ids = annotations_by_image[image_id]\n","            for cat_id in category_ids:\n","                if cat_id in cat_id_to_idx:\n","                    idx = cat_id_to_idx[cat_id]\n","                    label_vector[idx] = 1.0\n","\n","        image_paths.append(image_path)\n","        labels_list.append(label_vector)\n","\n","    # Convert to numpy arrays\n","    image_paths = np.array(image_paths)\n","    labels = np.array(labels_list)\n","\n","    # Create metadata dictionary\n","    metadata = {\n","        'num_classes': num_classes,\n","        'cat_id_to_idx': cat_id_to_idx,\n","        'idx_to_cat_id': idx_to_cat_id,\n","        'categories': categories,\n","        'image_size': image_size,\n","        'subset': subset,\n","        'num_samples': len(image_paths)\n","    }\n","\n","    print(f\"Loaded {subset} set: {len(image_paths)} images, {num_classes} classes\")\n","    print(f\"Labels shape: {labels.shape}\")\n","\n","    return image_paths, labels, metadata\n","\n","\n","def create_tf_dataset(\n","    image_paths: np.ndarray,\n","    labels: np.ndarray,\n","    metadata: Dict,\n","    batch_size: int = 32\n",") -> tf.data.Dataset:\n","    \"\"\"\n","    Create a TensorFlow dataset from image paths and labels for EfficientNetV2.\n","    \"\"\"\n","    image_size = metadata['image_size']\n","\n","    def load_and_preprocess_image(image_path, label):\n","        # Read image\n","        image = tf.io.read_file(image_path)\n","        image = tf.image.decode_jpeg(image, channels=3)\n","\n","        # Resize\n","        image = tf.image.resize(image, image_size)\n","\n","        # Preprocess for EfficientNet (scales to [-1, 1])\n","        image = tf.keras.applications.efficientnet_v2.preprocess_input(image)\n","\n","        return image, label\n","\n","    # Create dataset\n","    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n","    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset\n","\n","train_image_paths, train_labels, train_metadata = transform_coco_to_multilabel(\n","    dataset.location,\n","    subset='train',\n","    image_size=(640, 640)\n",")\n","\n","train_dataset = create_tf_dataset(\n","    train_image_paths,\n","    train_labels,\n","    train_metadata,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"odINh0pF3tox"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"CXuF9EPPVXDk"},"source":["## Train multi-label classification EfficientNetV2 model with dataset\n","\n","We train the EfficientNetV2 model with early stopping, a model checkpoint (to save the best resultant model), and display the required metrics for our evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mg8VP7hQV2Ux","outputId":"adca9ad5-1b5d-4b5d-8d67-fbce2942d461","executionInfo":{"status":"ok","timestamp":1768718938571,"user_tz":360,"elapsed":420506,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded valid set: 440 images, 7 classes\n","Labels shape: (440, 7)\n","Epoch 1/50\n","\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668ms/step - auc: 0.6179 - loss: 0.4467 - macro_f1: 0.1540 - micro_f1: 0.2965 - subset_accuracy: 0.3247\n","Epoch 1: val_loss improved from inf to 0.24937, saving model to best_model.keras\n","\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 942ms/step - auc: 0.6186 - loss: 0.4460 - macro_f1: 0.1541 - micro_f1: 0.2970 - subset_accuracy: 0.3253 - val_auc: 0.8804 - val_loss: 0.2494 - val_macro_f1: 0.3485 - val_micro_f1: 0.5643 - val_subset_accuracy: 0.5227\n","Epoch 2/50\n","\u001b[1m144/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - auc: 0.9190 - loss: 0.2171 - macro_f1: 0.4171 - micro_f1: 0.6089 - subset_accuracy: 0.5425\n","Epoch 2: val_loss improved from 0.24937 to 0.16299, saving model to best_model.keras\n","\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 132ms/step - auc: 0.9193 - loss: 0.2167 - macro_f1: 0.4187 - micro_f1: 0.6098 - subset_accuracy: 0.5433 - val_auc: 0.9537 - val_loss: 0.1630 - val_macro_f1: 0.6792 - val_micro_f1: 0.7543 - val_subset_accuracy: 0.6841\n","Epoch 3/50\n","\u001b[1m144/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - auc: 0.9802 - loss: 0.1235 - macro_f1: 0.7852 - micro_f1: 0.8366 - subset_accuracy: 0.7471\n","Epoch 3: val_loss improved from 0.16299 to 0.12557, saving model to best_model.keras\n","\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 131ms/step - auc: 0.9803 - loss: 0.1233 - macro_f1: 0.7858 - micro_f1: 0.8369 - subset_accuracy: 0.7477 - val_auc: 0.9703 - val_loss: 0.1256 - val_macro_f1: 0.7948 - val_micro_f1: 0.8344 - val_subset_accuracy: 0.7545\n","Epoch 4/50\n","\u001b[1m144/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - auc: 0.9959 - loss: 0.0683 - macro_f1: 0.9117 - micro_f1: 0.9285 - subset_accuracy: 0.8720\n","Epoch 4: val_loss improved from 0.12557 to 0.12041, saving model to best_model.keras\n","\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 131ms/step - auc: 0.9959 - loss: 0.0682 - macro_f1: 0.9118 - micro_f1: 0.9286 - subset_accuracy: 0.8723 - val_auc: 0.9706 - val_loss: 0.1204 - val_macro_f1: 0.8285 - val_micro_f1: 0.8489 - val_subset_accuracy: 0.7705\n","Epoch 5/50\n","\u001b[1m144/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - auc: 0.9988 - loss: 0.0414 - macro_f1: 0.9565 - micro_f1: 0.9612 - subset_accuracy: 0.9287\n","Epoch 5: val_loss did not improve from 0.12041\n","\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 123ms/step - auc: 0.9988 - loss: 0.0414 - macro_f1: 0.9566 - micro_f1: 0.9613 - subset_accuracy: 0.9290 - val_auc: 0.9686 - val_loss: 0.1245 - val_macro_f1: 0.8423 - val_micro_f1: 0.8540 - val_subset_accuracy: 0.7795\n","Epoch 6/50\n","\u001b[1m144/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - auc: 0.9996 - loss: 0.0256 - macro_f1: 0.9789 - micro_f1: 0.9813 - subset_accuracy: 0.9641\n","Epoch 6: val_loss did not improve from 0.12041\n","\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 123ms/step - auc: 0.9996 - loss: 0.0256 - macro_f1: 0.9789 - micro_f1: 0.9813 - subset_accuracy: 0.9641 - val_auc: 0.9668 - val_loss: 0.1229 - val_macro_f1: 0.8361 - val_micro_f1: 0.8514 - val_subset_accuracy: 0.7705\n","Epoch 7/50\n","\u001b[1m144/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - auc: 0.9998 - loss: 0.0182 - macro_f1: 0.9861 - micro_f1: 0.9881 - subset_accuracy: 0.9779\n","Epoch 7: val_loss did not improve from 0.12041\n","\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 123ms/step - auc: 0.9998 - loss: 0.0182 - macro_f1: 0.9861 - micro_f1: 0.9881 - subset_accuracy: 0.9779 - val_auc: 0.9687 - val_loss: 0.1270 - val_macro_f1: 0.8412 - val_micro_f1: 0.8548 - val_subset_accuracy: 0.7795\n","Epoch 8/50\n","\u001b[1m144/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - auc: 0.9999 - loss: 0.0140 - macro_f1: 0.9896 - micro_f1: 0.9906 - subset_accuracy: 0.9821\n","Epoch 8: val_loss did not improve from 0.12041\n","\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 123ms/step - auc: 0.9999 - loss: 0.0140 - macro_f1: 0.9896 - micro_f1: 0.9906 - subset_accuracy: 0.9821 - val_auc: 0.9681 - val_loss: 0.1303 - val_macro_f1: 0.8424 - val_micro_f1: 0.8585 - val_subset_accuracy: 0.7795\n","Epoch 9/50\n","\u001b[1m144/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - auc: 0.9999 - loss: 0.0118 - macro_f1: 0.9914 - micro_f1: 0.9925 - subset_accuracy: 0.9861\n","Epoch 9: val_loss did not improve from 0.12041\n","\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 123ms/step - auc: 0.9999 - loss: 0.0117 - macro_f1: 0.9914 - micro_f1: 0.9925 - subset_accuracy: 0.9861 - val_auc: 0.9694 - val_loss: 0.1256 - val_macro_f1: 0.8540 - val_micro_f1: 0.8649 - val_subset_accuracy: 0.7795\n","Epoch 9: early stopping\n","Restoring model weights from the end of the best epoch: 4.\n"]}],"source":["from tensorflow.keras import layers, Model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import tensorflow as tf\n","\n","valid_image_paths, valid_labels_train, valid_metadata = transform_coco_to_multilabel(\n","    dataset.location,\n","    subset='valid',\n","    image_size=(640, 640)\n",")\n","\n","valid_dataset = create_tf_dataset(\n","    valid_image_paths,\n","    valid_labels_train,\n","    valid_metadata,\n",")\n","\n","# Custom F1 Score metric (this is Micro F1)\n","class MicroF1Score(tf.keras.metrics.Metric):\n","    def __init__(self, name='micro_f1', **kwargs):\n","        super().__init__(name=name, **kwargs)\n","        self.precision = tf.keras.metrics.Precision()\n","        self.recall = tf.keras.metrics.Recall()\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        self.precision.update_state(y_true, y_pred, sample_weight)\n","        self.recall.update_state(y_true, y_pred, sample_weight)\n","\n","    def result(self):\n","        p = self.precision.result()\n","        r = self.recall.result()\n","        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n","\n","    def reset_state(self):\n","        self.precision.reset_state()\n","        self.recall.reset_state()\n","\n","# Custom Macro F1 Score metric\n","class MacroF1Score(tf.keras.metrics.Metric):\n","    def __init__(self, num_classes, name='macro_f1', **kwargs):\n","        super().__init__(name=name, **kwargs)\n","        self.num_classes = num_classes\n","        self.precisions = [tf.keras.metrics.Precision() for _ in range(num_classes)]\n","        self.recalls = [tf.keras.metrics.Recall() for _ in range(num_classes)]\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        for i in range(self.num_classes):\n","            self.precisions[i].update_state(y_true[:, i], y_pred[:, i], sample_weight)\n","            self.recalls[i].update_state(y_true[:, i], y_pred[:, i], sample_weight)\n","\n","    def result(self):\n","        f1_scores = []\n","        for i in range(self.num_classes):\n","            p = self.precisions[i].result()\n","            r = self.recalls[i].result()\n","            f1 = 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n","            f1_scores.append(f1)\n","        return tf.reduce_mean(f1_scores)\n","\n","    def reset_state(self):\n","        for i in range(self.num_classes):\n","            self.precisions[i].reset_state()\n","            self.recalls[i].reset_state()\n","\n","# Custom Subset Accuracy metric\n","class SubsetAccuracy(tf.keras.metrics.Metric):\n","    def __init__(self, name='subset_accuracy', threshold=0.5, **kwargs):\n","        super().__init__(name=name, **kwargs)\n","        self.threshold = threshold\n","        self.correct = self.add_weight(name='correct', initializer='zeros')\n","        self.total = self.add_weight(name='total', initializer='zeros')\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        y_pred_binary = tf.cast(y_pred >= self.threshold, tf.float32)\n","        exact_matches = tf.reduce_all(tf.equal(y_true, y_pred_binary), axis=1)\n","        self.correct.assign_add(tf.reduce_sum(tf.cast(exact_matches, tf.float32)))\n","        self.total.assign_add(tf.cast(tf.shape(y_true)[0], tf.float32))\n","\n","    def result(self):\n","        return self.correct / (self.total + tf.keras.backend.epsilon())\n","\n","    def reset_state(self):\n","        self.correct.assign(0.0)\n","        self.total.assign(0.0)\n","\n","# Build EfficientNetV2 multi-label classification model\n","base_model = tf.keras.applications.EfficientNetV2B0(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(640, 640, 3),\n","    pooling='avg'\n",")\n","\n","# Unfreeze base model for fine-tuning\n","base_model.trainable = True\n","\n","# Build model\n","inputs = tf.keras.Input(shape=(640, 640, 3))\n","x = base_model(inputs, training=True)\n","x = layers.Dropout(0.2)(x)\n","outputs = layers.Dense(train_metadata['num_classes'], activation='sigmoid')(x)\n","\n","model = Model(inputs=inputs, outputs=outputs)\n","\n","# Compile with all requested metrics\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n","    loss='binary_crossentropy',\n","    metrics=[\n","        MicroF1Score(name='micro_f1'),\n","        MacroF1Score(num_classes=train_metadata['num_classes'], name='macro_f1'),\n","        tf.keras.metrics.AUC(name='auc', multi_label=True),\n","        SubsetAccuracy(name='subset_accuracy', threshold=0.5)\n","    ]\n",")\n","\n","# Callbacks\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    restore_best_weights=True,\n","    verbose=1\n",")\n","\n","model_checkpoint = ModelCheckpoint(\n","    filepath='best_model.keras',\n","    monitor='val_loss',\n","    save_best_only=True,\n","    verbose=1\n",")\n","\n","# Train the model\n","history = model.fit(\n","    train_dataset,\n","    validation_data=valid_dataset,\n","    epochs=50,\n","    callbacks=[early_stopping, model_checkpoint],\n","    verbose=1\n",")\n","\n","# Save the model\n","model.save('efficientnet_multilabel_model.keras')"]},{"cell_type":"markdown","metadata":{"id":"83a7g8nff5n5"},"source":["## Run predictions on test set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCi2cHdSxFxz","outputId":"c81003bb-75c9-4398-d884-31ef89b533ff","executionInfo":{"status":"ok","timestamp":1768718975358,"user_tz":360,"elapsed":36783,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded test set: 218 images, 7 classes\n","Labels shape: (218, 7)\n","Generating predictions...\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4s/step\n","\n","==================================================\n","TEST SET METRICS\n","==================================================\n","Subset Accuracy: 0.7844\n","Micro F1:        0.8548\n","Macro F1:        0.8490\n","\n","==================================================\n","F1 SCORE PER CLASS\n","==================================================\n","french_fries: 0.7429\n","fried_chicken: 0.9268\n","hamburger: 0.9655\n","ice_cream: 0.8780\n","junk_food_logo: 0.8696\n","pizza: 0.8571\n","soda: 0.7027\n"]}],"source":["import numpy as np\n","from sklearn.metrics import f1_score, accuracy_score\n","\n","# Load the test dataset\n","test_image_paths, test_labels, test_metadata = transform_coco_to_multilabel(\n","    dataset.location,\n","    subset='test',\n","    image_size=(640, 640)\n",")\n","\n","test_dataset = create_tf_dataset(\n","    test_image_paths,\n","    test_labels,\n","    test_metadata,\n",")\n","\n","# Load the best model (no custom objects needed)\n","best_model = tf.keras.models.load_model('best_model.keras', compile=False)\n","\n","# Generate predictions\n","print(\"Generating predictions...\")\n","y_pred_probs = best_model.predict(test_dataset, verbose=1)\n","y_pred = (y_pred_probs > 0.5).astype(int)\n","\n","# Get true labels\n","y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n","\n","# Calculate metrics\n","print(\"\\n\" + \"=\" * 50)\n","print(\"TEST SET METRICS\")\n","print(\"=\" * 50)\n","\n","subset_accuracy = accuracy_score(y_true, y_pred)\n","print(f\"Subset Accuracy: {subset_accuracy:.4f}\")\n","micro_f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n","print(f\"Micro F1:        {micro_f1:.4f}\")\n","macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n","print(f\"Macro F1:        {macro_f1:.4f}\")\n","\n","# F1 score per class\n","print(\"\\n\" + \"=\" * 50)\n","print(\"F1 SCORE PER CLASS\")\n","print(\"=\" * 50)\n","class_names = [cat['name'] for cat in sorted(test_metadata['categories'], key=lambda x: x['id'])]\n","f1_per_class = f1_score(y_true, y_pred, average=None, zero_division=0)\n","for class_name, f1 in zip(class_names, f1_per_class):\n","    print(f\"{class_name}: {f1:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"uHcfBK811jN0"},"source":["## Real images test\n","\n","Let's test the trained CNN model on random images from the test set with multi-label prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1bmz6NXPK7rvN95E-5mqwXc-Qu4RnLkh7"},"id":"RKgQQ4wu1jN0","executionInfo":{"status":"ok","timestamp":1768718994363,"user_tz":360,"elapsed":18997,"user":{"displayName":"Jose Andrés","userId":"08637818255854367082"}},"outputId":"76c65536-a3ae-46de-a9e5-c8fcbc0e7f99"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import random\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","from PIL import Image as PILImage\n","\n","# Get indices of images that have at least one label (interesting images)\n","positive_indices = [\n","    i for i, labels_vector in enumerate(test_labels)\n","    if sum(labels_vector) > 0  # Has at least one label\n","]\n","\n","# Pick 5 random test images with labels\n","test_indices = random.sample(positive_indices, min(5, len(positive_indices)))\n","\n","# Define colors for each class\n","class_colors = {\n","    \"french_fries\": \"#F39C12\",\n","    \"fried_chicken\": \"#E67E22\",\n","    \"hamburger\": \"#8B4513\",\n","    \"ice_cream\": \"#96CEB4\",\n","    \"junk_food_logo\": \"#FFEAA7\",\n","    \"pizza\": \"#FD79A8\",\n","    \"soda\": \"#A29BFE\"\n","}\n","\n","for idx, random_idx in enumerate(test_indices, 1):\n","    random_image_path = test_image_paths[random_idx]\n","    true_labels_vector = test_labels[random_idx]\n","    true_labels = [class_names[i] for i, val in enumerate(true_labels_vector) if val == 1]\n","\n","    print(f\"{'='*60}\")\n","    print(f\"Image {idx}/5: {random_image_path}\")\n","    print('='*60)\n","\n","    # Load and preprocess the image\n","    image = PILImage.open(random_image_path).convert(\"RGB\")\n","    image_resized = image.resize((640, 640))\n","    image_array = np.array(image_resized, dtype=np.float32)\n","    # Use the same preprocessing as during training (scales to [-1, 1])\n","    image_array = tf.keras.applications.efficientnet_v2.preprocess_input(image_array)\n","    image_batch = np.expand_dims(image_array, axis=0)\n","\n","    # Run inference\n","    pred_probs = best_model.predict(image_batch, verbose=0)[0]\n","    pred_labels_vector = (pred_probs > 0.5).astype(int)\n","    predicted_labels = [class_names[i] for i, val in enumerate(pred_labels_vector) if val == 1]\n","\n","    # Display the image with predictions\n","    fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n","    ax.imshow(image)\n","    ax.axis(\"off\")\n","\n","    # Create label badges at the bottom\n","    num_labels = len(predicted_labels) if predicted_labels else 1\n","    badge_width = 0.18\n","    badge_spacing = 0.02\n","    total_width = num_labels * badge_width + (num_labels - 1) * badge_spacing\n","    start_x = 0.5 - total_width / 2\n","\n","    if predicted_labels:\n","        for i, label in enumerate(predicted_labels):\n","            x_pos = start_x + i * (badge_width + badge_spacing)\n","            color = class_colors.get(label, \"#95A5A6\")\n","\n","            badge = mpatches.FancyBboxPatch(\n","                (x_pos, -0.08), badge_width, 0.05,\n","                boxstyle=\"round,pad=0.01\",\n","                facecolor=color,\n","                edgecolor=\"white\",\n","                linewidth=2,\n","                transform=ax.transAxes,\n","                clip_on=False\n","            )\n","            ax.add_patch(badge)\n","            ax.text(\n","                x_pos + badge_width / 2, -0.055,\n","                label.upper(),\n","                transform=ax.transAxes,\n","                fontsize=9,\n","                fontweight=\"bold\",\n","                color=\"white\" if label != \"junk_food_logo\" else \"black\",\n","                ha=\"center\",\n","                va=\"center\"\n","            )\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    print(f\"Model: EfficientNetV2B0 (CNN)\")\n","    print(f\"Predicted labels: {predicted_labels if predicted_labels else '(none)'}\")\n","    print(f\"True labels: {true_labels if true_labels else '(none)'}\")\n","\n","    print(f\"All class probabilities:\")\n","    sorted_probs = sorted(zip(class_names, pred_probs), key=lambda x: x[1], reverse=True)\n","    for cls, prob in sorted_probs:\n","        marker = \">\" if prob > 0.5 else \" \"\n","        print(f\"  {marker} {cls}: {prob:.3f}\")\n","\n","    correct_preds = set(predicted_labels) & set(true_labels)\n","    false_positives = set(predicted_labels) - set(true_labels)\n","    false_negatives = set(true_labels) - set(predicted_labels)\n","    print(f\"Correct predictions: {list(correct_preds) if correct_preds else '(none)'}\")\n","    print(f\"False positives: {list(false_positives) if false_positives else '(none)'}\")\n","    print(f\"False negatives: {list(false_negatives) if false_negatives else '(none)'}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}